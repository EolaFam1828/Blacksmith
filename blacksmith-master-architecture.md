# Blacksmith â€” Master Architecture Document

> Agents that build agents. Not because it's clever â€” because it's cheaper.

**Version**: 2.1.1 â€” Consolidated
**Date**: February 26, 2026
**Author**: Jake + Claude

---

## Table of Contents

1. Philosophy & Core Insight
2. System Architecture
3. The Identity Layer (Intent.md + OrchestratorPrompt.md)
4. The Brain (NotebookLM Multi-Notebook Topology)
5. Model Capability Registry (MCR)
6. Orchestrator Design
7. Dynamic Agent Assembly
8. Sub-Agent Architecture
9. Ephemeral Agent Lifecycle
10. Task Teardown & Prerequisites System
11. The Compounding Loop
12. Token Economics
13. Ecosystem Borrowing
14. CLI Commands
15. Directory Structure & Config
16. Build Order
17. Domain Agnosticism
18. What This Is NOT

---

## 1. Philosophy & Core Insight

Every AI framework today does this:

```
Human â†’ Static System Prompt + Static Tools + Static Memory â†’ Model â†’ Output
```

The problem: that static context is 95% irrelevant to any given task. You're
paying to send a 10,000-token system prompt when the task needs 200 tokens of
instruction. OpenClaw's SOUL.md, AGENTS.md, memory files, skills â€” all loaded
every single time, whether relevant or not. That's where the token burn lives.

Blacksmith does this:

```
Human â†’ Orchestrator (lightweight classification + dynamic agent assembly)
       â†’ Purpose-Built Ephemeral Agent (generated per-task)
       â†’ Execute â†’ Compress â†’ Store â†’ Teardown
```

The orchestrator spends ~500 tokens classifying your task and generating a
precision-targeted agent spec. That agent executes with ONLY the context
it needs. Net result: fewer total tokens, higher quality output.

**It LOOKS like it should eat tokens fast. It doesn't. Because precision > volume.**

Three rules:

1. Never spend a cloud token on something Ollama can handle locally
2. Never add abstraction that doesn't directly reduce cost or increase quality
3. Every token spent gets logged. No silent burns.

---

## 2. System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HUMAN INPUT                                  â”‚
â”‚                  (natural language task)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR LAYER                                 â”‚
â”‚           (Reads: OrchestratorPrompt.md + Intent.md)                 â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚    Task      â”‚  â”‚  Query Brain     â”‚  â”‚   Agent      â”‚           â”‚
â”‚  â”‚Classificationâ”‚â†’ â”‚  (NotebookLM)    â”‚â†’ â”‚  Assembly    â”‚           â”‚
â”‚  â”‚              â”‚  â”‚                  â”‚  â”‚  (Dynamic)   â”‚           â”‚
â”‚  â”‚ Tier 1:     â”‚  â”‚ Routes to:       â”‚  â”‚              â”‚           â”‚
â”‚  â”‚  Pattern    â”‚  â”‚ - models notebookâ”‚  â”‚ Generates:   â”‚           â”‚
â”‚  â”‚  match      â”‚  â”‚ - project nb     â”‚  â”‚ - soul.md    â”‚           â”‚
â”‚  â”‚             â”‚  â”‚ - history nb     â”‚  â”‚ - agents.md  â”‚           â”‚
â”‚  â”‚ Tier 2:     â”‚  â”‚ - errors nb      â”‚  â”‚ - memory.md  â”‚           â”‚
â”‚  â”‚  Brain      â”‚  â”‚ - reference nb   â”‚  â”‚   (prereqs)  â”‚           â”‚
â”‚  â”‚  query      â”‚  â”‚                  â”‚  â”‚ - skills.md  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ - runtime.md â”‚           â”‚
â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                    â”‚ Cost Efficiency  â”‚                              â”‚
â”‚                    â”‚ Guard            â”‚                              â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EPHEMERAL AGENT EXECUTION                         â”‚
â”‚              (Purpose-built, single-use)                             â”‚
â”‚                                                                      â”‚
â”‚  soul.md â† Identity from Intent.md department                        â”‚
â”‚  memory.md â† prerequisites.md from NotebookLM query                  â”‚
â”‚  skills.md â† Only tools needed for THIS task                         â”‚
â”‚  runtime.md â† Model, limits, timeout from Brain recommendation       â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  AGENTIC LOOP (with optional sub-agent dispatch)             â”‚   â”‚
â”‚  â”‚  intake â†’ context â†’ inference â†’ tool exec â†’ output           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TASK TEARDOWN                                      â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Compress â”‚â†’ â”‚ Route Summary â”‚â†’ â”‚  Log to  â”‚â†’ â”‚   Teardown    â”‚  â”‚
â”‚  â”‚ Output   â”‚  â”‚ to correct   â”‚  â”‚  Ledger  â”‚  â”‚   Agent Spec  â”‚  â”‚
â”‚  â”‚ (/compactâ”‚  â”‚ NotebookLM   â”‚  â”‚ (SQLite) â”‚  â”‚   (ephemeral) â”‚  â”‚
â”‚  â”‚  style)  â”‚  â”‚ notebook(s)  â”‚  â”‚          â”‚  â”‚               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â”‚                                             â”‚
â”‚                        â–¼                                             â”‚
â”‚               Brain now has MORE context                             â”‚
â”‚               for the NEXT task's prerequisites                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Available Backends

```
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      â”‚      â”‚      â”‚      â”‚      â”‚                  â”‚
â”‚Claudeâ”‚Geminiâ”‚Codex â”‚Jules â”‚Ollamaâ”‚   GitHub CLI     â”‚
â”‚ Code â”‚ CLI  â”‚ CLI  â”‚ CLI  â”‚(local)â”‚  (native)       â”‚
â”‚      â”‚      â”‚      â”‚      â”‚      â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. The Identity Layer

Two files define WHO Blacksmith is and HOW it behaves. Together they are the
organizational DNA that every agent inherits from.

### Intent.md â€” The Organizational DNA

You write this. It rarely changes. It defines mission, values, and the
sub-agent architecture via "Departments."

Location: `~/.blacksmith/Intent.md`

```markdown
# Intent.md â€” Blacksmith System Identity

## Mission
Build and maintain high-quality software systems with maximum efficiency
and minimum waste. Every token spent should produce measurable value.

## Vision
A personal AI development environment that compounds knowledge over time,
making each interaction smarter than the last. Not a product â€” a workshop.

## Values
- **Precision over volume**: A 200-token targeted prompt beats a 10,000-token generic one
- **Local first**: Never send to the cloud what can be handled on the machine
- **Transparency**: Every cost visible, every decision traceable
- **Composability**: Small tools, clear interfaces, replaceable parts
- **Earned complexity**: Add abstraction only when simplicity fails

## Principles
- Ship working code, not perfect architecture
- Measure everything, optimize what matters
- Human checkpoints before destructive actions
- Fail fast, fail cheap (try Ollama first, escalate if needed)
- Context is king â€” the right 500 tokens beat the wrong 50,000

## Owner Context
- Name: Jake
- Role: Corporate Development Officer (current), AI Engineer (target)
- Technical depth: Infrastructure, DevOps, AI/ML, full-stack
- Projects: Blacksmith, Aether, CampaignOS, Eola Gateway homelab
- Communication style: Direct, technical, no fluff
- Decision framework: Pragmatic â€” "does this actually work?"

## Departments (Sub-Agent Architecture)

### Engineering
- **Focus**: Code quality, architecture, debugging, refactoring
- **Default models**: Claude Code (complex), Ollama (simple)
- **Review standard**: Two-stage (spec compliance â†’ quality)
- **Methodology**: Design â†’ Plan â†’ Implement â†’ Test â†’ Review

### Research
- **Focus**: Technology evaluation, comparison, synthesis
- **Default models**: Gemini Pro (deep), Gemini Flash (quick)
- **Output standard**: Structured findings with sources
- **Methodology**: Define scope â†’ Multi-source gather â†’ Synthesize â†’ Recommend

### Infrastructure
- **Focus**: Homelab, cloud, networking, deployment, IaC
- **Default models**: Claude Code (IaC), Gemini Pro (troubleshooting)
- **Safety standard**: Human checkpoint before any destructive action
- **Methodology**: Diagnose â†’ Plan â†’ Execute â†’ Verify â†’ Document

### Operations
- **Focus**: Git workflow, commit messages, PR management, CI/CD
- **Default models**: Ollama (commits), GitHub CLI (native ops)
- **Automation level**: Full auto for commits, human approval for merges
- **Methodology**: Detect change â†’ Generate â†’ Validate â†’ Apply

## File Tree (Project Map)
<!-- Auto-generated by `blacksmith map` â€” updated on each run -->
```

### How Intent.md Flows Through the System

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Intent.md  â”‚ â† You write this (rarely changes)
                    â”‚            â”‚
                    â”‚ Mission    â”‚
                    â”‚ Values     â”‚
                    â”‚ Principles â”‚
                    â”‚ Departmentsâ”‚
                    â”‚ File Tree  â”‚
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚           â”‚               â”‚
              â–¼           â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Orchestrator â”‚ â”‚ Agent    â”‚  â”‚ Sub-Agent      â”‚
    â”‚Prompt.md    â”‚ â”‚ Assembly â”‚  â”‚ Assembly       â”‚
    â”‚             â”‚ â”‚          â”‚  â”‚                â”‚
    â”‚ Reads:      â”‚ â”‚ Inherits:â”‚  â”‚ Inherits:      â”‚
    â”‚ - Routing   â”‚ â”‚ - Values â”‚  â”‚ - Department   â”‚
    â”‚   rules     â”‚ â”‚ - Tone   â”‚  â”‚   focus        â”‚
    â”‚ - Tier logicâ”‚ â”‚ - Owner  â”‚  â”‚ - Review       â”‚
    â”‚ - Cost guardâ”‚ â”‚   contextâ”‚  â”‚   standards    â”‚
    â”‚ - Checkpts  â”‚ â”‚ - Dept   â”‚  â”‚ - Safety rules â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   config â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OrchestratorPrompt.md â€” Orchestrator Behavior

This is the system prompt for the orchestrator itself. Unlike Intent.md
(which you write and rarely change), this gets refined as you use the system.

Location: `~/.blacksmith/OrchestratorPrompt.md`

```markdown
# OrchestratorPrompt.md â€” Orchestrator Behavior

## Role
You are the Blacksmith orchestrator. Your job is to classify incoming tasks,
query the Blacksmith Brain (NotebookLM) for relevant context and model selection,
assemble a purpose-built ephemeral agent, and route execution to the right
backend. You are NOT the executor â€” you are the dispatcher.

## Decision Process

1. **Receive** human input (task description)
2. **Classify** task type, complexity, and department (per Intent.md)
3. **Query Brain** for:
   - Model recommendation (grounded in benchmarks + past performance)
   - Relevant prerequisites (past tasks, errors, decisions)
   - Cost estimate
4. **Assemble** ephemeral agent spec:
   - soul (identity + tone, derived from Intent.md department)
   - agents (sub-agent definitions if multi-step)
   - memory (prerequisites from Brain query)
   - skills (tool schemas needed for this specific task)
   - runtime (model, limits, timeout)
5. **Estimate** cost and flag if over threshold
6. **Execute** or request human confirmation
7. **Teardown** â€” compress output, push to Brain, log to ledger

## Routing Rules

### Tier 1: Deterministic (zero LLM cost)
Pattern-matched commands route without any model inference:
- `blacksmith commit` â†’ Ollama (always)
- `blacksmith ask --backend X` â†’ direct passthrough
- `blacksmith spend` / `blacksmith config` / `blacksmith brain` â†’ internal commands
- Known command + simple args â†’ deterministic routing

### Tier 2: Brain-Assisted (NotebookLM query)
For ambiguous or complex tasks:
- Query the Brain with task description + project context
- Brain returns: model recommendation, prerequisites, cost estimate
- Generate ephemeral agent spec from Brain response

### Escalation Rules
- If Ollama response quality < threshold â†’ re-route to Gemini Flash
- If Gemini Flash insufficient â†’ escalate to Gemini Pro or Claude
- Never escalate Jules (async-only, escalation doesn't apply)
- Always inform user when escalating

## Cost Guard
- Warn if single task estimated > $0.50
- Hard stop if estimated > $2.00 (require explicit `--force`)
- Daily spend summary auto-generated at midnight

## Human Checkpoints
ALWAYS require confirmation before:
- Deleting files or branches
- Pushing to remote repositories
- Running deployment commands
- Any operation flagged as destructive in the agent spec

## Self-Improvement
After every 50 tasks, generate a routing performance summary:
- Which model selections were optimal?
- Where did escalations happen?
- What patterns could be moved to Tier 1?
Update this prompt with learned patterns.
```

---

## 4. The Brain (NotebookLM Multi-Notebook Topology)

NotebookLM is flat â€” no folders, no nesting, no tagging within a notebook.
Dumping everything into one notebook degrades retrieval quality. The solution
is purpose-built notebooks with query routing at the orchestrator level.

One brain, many lobes. Each notebook is a specialized knowledge domain.

### Notebook Topology

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FORGE BRAIN (Notebook Registry)                â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ğŸ“Š Models   â”‚  â”‚  ğŸ”§ Projects â”‚  â”‚  ğŸ“‹ Task History      â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚                       â”‚ â”‚
â”‚  â”‚ benchmarks   â”‚  â”‚ One notebook â”‚  â”‚  One notebook per     â”‚ â”‚
â”‚  â”‚ pricing      â”‚  â”‚ PER project  â”‚  â”‚  department           â”‚ â”‚
â”‚  â”‚ capabilities â”‚  â”‚              â”‚  â”‚  (from Intent.md)     â”‚ â”‚
â”‚  â”‚ routing rulesâ”‚  â”‚ blacksmith/  â”‚  â”‚                       â”‚ â”‚
â”‚  â”‚ comparisons  â”‚  â”‚ aether/      â”‚  â”‚  engineering-history/ â”‚ â”‚
â”‚  â”‚              â”‚  â”‚ campaignos/  â”‚  â”‚  research-history/    â”‚ â”‚
â”‚  â”‚              â”‚  â”‚ eola-gw/     â”‚  â”‚  infra-history/       â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚  ops-history/         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚  ğŸ› Errors   â”‚  â”‚  ğŸ“– Referenceâ”‚                             â”‚
â”‚  â”‚              â”‚  â”‚              â”‚                             â”‚
â”‚  â”‚ error patternsâ”‚  â”‚ Intent.md   â”‚                             â”‚
â”‚  â”‚ resolutions  â”‚  â”‚ style guides â”‚                             â”‚
â”‚  â”‚ stack traces â”‚  â”‚ conventions  â”‚                             â”‚
â”‚  â”‚ workarounds  â”‚  â”‚ API docs     â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Notebook Definitions

```yaml
# ~/.blacksmith/brain.yaml â€” Notebook Registry

notebooks:

  models:
    id: null                    # populated after `blacksmith brain init`
    purpose: "Model selection intelligence"
    description: >
      Benchmarks, pricing, capability profiles, and routing principles
      for all available AI models. Queried during Tier 2 orchestration.
    sources:
      permanent:
        - "model-benchmarks.md"
        - "model-pricing.md"
        - "model-capabilities.md"
        - "routing-principles.md"
        - "model-comparison-notes.md"
      refresh:
        benchmarks: weekly
        pricing: monthly
    max_sources: 30

  # One per project â€” created via `blacksmith brain project add <name>`
  project-blacksmith:
    id: null
    purpose: "Blacksmith project knowledge"
    description: >
      Architecture decisions, file structure, dependency choices,
      patterns, and conventions specific to the Blacksmith project.
    sources:
      permanent:
        - "blacksmith-architecture.md"
        - "blacksmith-file-tree.md"
        - "blacksmith-conventions.md"
      dynamic:
        - task summaries tagged with project:blacksmith
    max_sources: 50

  project-aether:
    id: null
    purpose: "Aether litigation intelligence platform knowledge"
    sources:
      permanent:
        - "aether-architecture.md"
        - "aether-data-models.md"
      dynamic:
        - task summaries tagged with project:aether
    max_sources: 50

  # Department history notebooks â€” one per Intent.md department
  history-engineering:
    id: null
    purpose: "Engineering task history and learned patterns"
    description: >
      Compressed summaries of all engineering tasks: code reviews,
      refactors, builds, debug sessions. Queried for prerequisites.
    sources:
      dynamic:
        - task summaries where department == "engineering"
    max_sources: 150
    archive:
      strategy: "quarterly_merge"
      keep_recent: 100
      merge_older_than_days: 60

  history-research:
    id: null
    purpose: "Research task history â€” findings, comparisons, evaluations"
    sources:
      dynamic:
        - task summaries where department == "research"
    max_sources: 100
    archive:
      strategy: "quarterly_merge"
      keep_recent: 75
      merge_older_than_days: 60

  history-infra:
    id: null
    purpose: "Infrastructure task history â€” deployments, configs, diagnostics"
    sources:
      dynamic:
        - task summaries where department == "infrastructure"
    max_sources: 100
    archive:
      strategy: "quarterly_merge"
      keep_recent: 75
      merge_older_than_days: 60

  history-ops:
    id: null
    purpose: "Operations task history â€” git workflows, CI/CD, automation"
    sources:
      dynamic:
        - task summaries where department == "operations"
    max_sources: 50
    archive:
      strategy: "quarterly_merge"
      keep_recent: 40
      merge_older_than_days: 90

  errors:
    id: null
    purpose: "Error patterns, stack traces, and resolutions"
    description: >
      Every error encountered during task execution, paired with
      its resolution. Queried when a new error appears to check
      if we've seen it before.
    sources:
      dynamic:
        - error summaries from failed/recovered tasks
    max_sources: 100
    archive:
      strategy: "deduplicate_and_merge"
      merge_threshold: 3     # same error 3+ times â†’ merge into single source

  reference:
    id: null
    purpose: "Stable reference material â€” conventions, guides, snippets"
    sources:
      permanent:
        - "Intent.md"
        - "coding-conventions.md"
        - "git-workflow.md"
        - "naming-conventions.md"
    max_sources: 30
```

### Brain Query Routing

The orchestrator doesn't just pick a model â€” it picks which notebook(s)
to query. Sometimes one, sometimes multiple. Queries run in parallel.

```javascript
function routeBrainQuery(task, classification) {
  const queries = [];

  // ALWAYS query models notebook for Tier 2 routing
  if (classification.tier === 2) {
    queries.push({
      notebook: 'models',
      query: `Best model for: ${task.type}, complexity: ${classification.complexity}`
    });
  }

  // Query the relevant project notebook if we know the project
  if (task.project) {
    queries.push({
      notebook: `project-${task.project}`,
      query: `Relevant context for: ${task.description}`
    });
  }

  // Query the relevant department history for prerequisites
  if (classification.department) {
    queries.push({
      notebook: `history-${classification.department}`,
      query: `Past tasks related to: ${task.description}. What prerequisites?`
    });
  }

  // If the task involves an error, check the error notebook
  if (classification.hasError || task.type === 'debug') {
    queries.push({
      notebook: 'errors',
      query: `Have we seen this before? ${task.errorSignature || task.description}`
    });
  }

  // For output-producing tasks, check conventions
  if (['build', 'refactor', 'commit'].includes(task.type)) {
    queries.push({
      notebook: 'reference',
      query: `Relevant conventions for: ${task.type}`
    });
  }

  return queries;  // Executed in parallel via Promise.allSettled
}
```

### Query Routing Examples

**Simple: `blacksmith commit`**
```
Tier 1 (pattern match) â†’ Ollama, no brain query needed
Notebooks queried: 0
```

**Medium: `blacksmith review src/api/auth.js`**
```
Tier 2 queries (parallel):
  1. models             â†’ "Best model for code review, ~3K tokens"
  2. project-blacksmith      â†’ "Context for src/api/auth.js"
  3. history-engineering â†’ "Past reviews of auth.js, auth patterns"
  4. reference          â†’ "Code review conventions"
```

**Complex: `blacksmith debug "ECONNREFUSED when calling Ollama from Docker"`**
```
Tier 2 queries (parallel):
  1. models       â†’ "Best model for debugging Docker networking"
  2. errors       â†’ "ECONNREFUSED Ollama Docker â€” seen before?"
  3. history-infra â†’ "Past Docker networking tasks"
  4. project-blacksmith â†’ "How does Blacksmith connect to Ollama?"

If errors notebook returns a match:
  â†’ Skip expensive debugging, surface the known fix
  â†’ "We hit this on 2/14. Fix: use host.docker.internal instead of localhost"
  â†’ Cost: ~$0.001 (just the notebook queries)
```

### Teardown â†’ Notebook Routing

Completed task summaries route to the RIGHT notebook(s):

```javascript
function routeTeardown(taskSummary) {
  const targets = [];

  // Always goes to department history
  targets.push(`history-${taskSummary.department}`);

  // Goes to project notebook if project-scoped
  if (taskSummary.project) {
    targets.push(`project-${taskSummary.project}`);
  }

  // Goes to errors notebook if errors were encountered
  if (taskSummary.errorsEncountered.length > 0) {
    targets.push('errors');
  }

  // Goes to models notebook if we learned about model performance
  if (taskSummary.escalated || taskSummary.modelPerformanceNote) {
    targets.push('models');
  }

  return targets;
}
```

### NotebookLM Access â€” Two Paths

**Path A: notebooklm-mcp-cli (Recommended for Phase 1)**
- Works with free/Pro NotebookLM accounts
- CLI + MCP server in one package
- No GCP billing required
- Community-maintained

```bash
pip install notebooklm-mcp-cli --break-system-packages
nlm login
nlm notebook create "Blacksmith Brain - Models"
nlm source add <notebook_id> --file ./model-capabilities.md
```

**Path B: NotebookLM Enterprise API (Future / Scale)**
- Requires Google Cloud project + billing
- Official API (alpha, Discovery Engine v1alpha)
- Better for production / high-volume / automation

**Recommendation**: Start with Path A. Migrate to Path B when you need
reliability guarantees or hit rate limits.

### Notebook Lifecycle Management

```
CREATE    â†’ `blacksmith brain init` or `blacksmith brain project add`
SEED      â†’ Permanent sources loaded (benchmarks, Intent.md)
GROW      â†’ Task teardowns push summaries to relevant notebooks
MONITOR   â†’ `blacksmith brain health` checks source counts + staleness
ARCHIVE   â†’ Quarterly: merge old summaries into compressed docs
            Errors: deduplicate repeated patterns
REFRESH   â†’ Weekly: re-scrape benchmarks. Monthly: check pricing.
RETIRE    â†’ `blacksmith brain project archive <name>` (export + delete)
```

### Scaling: When You Hit NotebookLM Limits

Free/Pro NotebookLM: ~50 sources per notebook, ~50 notebooks
Enterprise: higher limits, API access

If you outgrow free tier:

1. Aggressive archiving (quarterly merges keep source counts low)
2. Enterprise tier (if the value justifies the GCP cost)
3. Replace NotebookLM with self-hosted RAG (ChromaDB + Ollama embeddings)
   â€” same notebook topology, same query routing, different backend
   â€” the abstraction layer means swapping is a backend change, not an architecture change

---

## 5. Model Capability Registry (MCR)

The MCR defines what each model is good at, what it costs, and when to use it.
It lives as a source in the `models` NotebookLM notebook AND as a local YAML
file for Tier 1 pattern matching (zero LLM cost lookups).

Location: `~/.blacksmith/mcr.yaml` (local) + `models` notebook (Brain)

```yaml
# ~/.blacksmith/mcr.yaml â€” Model Capability Registry

models:
  claude-code:
    provider: anthropic
    access: cli
    context_window: 200000
    strengths:
      - agentic_code_editing
      - architecture_reasoning
      - debugging_complex
      - infrastructure_precision
      - safety_critical
    weaknesses:
      - cost_per_token
      - bulk_reading
    cost:
      input_per_1m: 3.00
      output_per_1m: 15.00
    speed: medium
    best_for:
      - "refactor multi-file codebase"
      - "debug production issue"
      - "design system architecture"
      - "write infrastructure as code"

  gemini-2.5-pro:
    provider: google
    access: cli
    context_window: 1048576
    strengths:
      - deep_reasoning
      - long_context_analysis
      - research_synthesis
      - orchestration
      - code_generation
      - cost_efficiency
    weaknesses:
      - agentic_file_editing
    cost:
      input_per_1m: 1.25
      output_per_1m: 10.00
    speed: medium
    best_for:
      - "research and compare technologies"
      - "analyze large codebase"
      - "synthesize multiple documents"
      - "novel problem requiring creative reasoning"

  gemini-2.5-flash:
    provider: google
    access: cli
    context_window: 1048576
    strengths:
      - speed
      - cost_efficiency
      - summarization
      - classification
    weaknesses:
      - complex_reasoning
      - precision_tasks
    cost:
      input_per_1m: 0.15
      output_per_1m: 0.60
    speed: fast
    best_for:
      - "quick classification"
      - "summarize document"
      - "triage issues"

  ollama-qwen2.5-coder:
    provider: local
    access: http
    context_window: 32768
    strengths:
      - zero_cost
      - privacy
      - speed
      - simple_code
      - commit_messages
      - quick_answers
    weaknesses:
      - complex_reasoning
      - long_context
      - multi_file
    cost:
      input_per_1m: 0.00
      output_per_1m: 0.00
    speed: fastest
    best_for:
      - "generate commit message"
      - "explain this regex"
      - "simple code snippet"
      - "quick factual question"

  ollama-deepseek-r1:
    provider: local
    access: http
    context_window: 65536
    strengths:
      - zero_cost
      - reasoning
      - code_analysis
      - math
    weaknesses:
      - speed
      - very_complex_tasks
    cost:
      input_per_1m: 0.00
      output_per_1m: 0.00
    speed: medium
    best_for:
      - "analyze algorithm complexity"
      - "debug logic error locally"
      - "explain technical concept"

  codex-cli:
    provider: openai
    access: cli
    context_window: 200000
    strengths:
      - fast_scaffolding
      - boilerplate
      - prototyping
    weaknesses:
      - deep_reasoning
    cost:
      input_per_1m: 2.50
      output_per_1m: 10.00
    speed: fast
    best_for:
      - "scaffold new project"
      - "generate boilerplate"
      - "quick prototype"

  jules-cli:
    provider: google
    access: cli
    context_window: null
    strengths:
      - async_execution
      - background_tasks
      - github_integration
    weaknesses:
      - interactive
      - speed
    cost:
      input_per_1m: null
      output_per_1m: null
    speed: slow
    best_for:
      - "fix this GitHub issue in the background"
      - "create PR for this feature"
      - "async code review"

routing_principles:
  - "Always try local (Ollama) first for tasks under 4K context that don't require frontier reasoning"
  - "Use Gemini Flash for classification and triage â€” it's 20x cheaper than Pro"
  - "Reserve Claude Code for tasks where precision has financial or safety consequences"
  - "Use Gemini Pro for novel/undefined problems â€” its parallel thinking excels at exploration"
  - "Jules is for async only â€” never block the user waiting for Jules"
  - "If a task could be handled by two models, pick the cheaper one and escalate if quality is low"
  - "The orchestrator itself should run on Gemini Flash (cheap, fast) not Pro"

last_updated: "2026-02-26"
benchmark_sources:
  - "https://lmarena.ai"
  - "https://livebench.ai"
  - "https://www.artificial-analysis.ai"
```

---

## 6. Orchestrator Design

The orchestrator is intentionally thin and cheap. Two tiers ensure most
commands cost nothing to route, and complex ones get brain-assisted routing.

### Two-Tier Orchestration

```
Tier 1: Pattern Matching (zero LLM cost)
â”œâ”€â”€ "blacksmith commit" â†’ always Ollama, always commit-message pattern
â”œâ”€â”€ "blacksmith ask --backend X" â†’ direct passthrough, no routing needed
â”œâ”€â”€ "blacksmith brain <query>" â†’ NotebookLM direct query
â”œâ”€â”€ Known command + simple args â†’ deterministic routing via MCR
â””â”€â”€ Everything else â†’ Tier 2

Tier 2: Brain-Assisted Classification
â”œâ”€â”€ Query relevant NotebookLM notebooks (parallel)
â”œâ”€â”€ Analyze task description against Brain results
â”œâ”€â”€ Determine department (from Intent.md)
â”œâ”€â”€ Estimate context size
â”œâ”€â”€ Determine if sub-agents are needed
â”œâ”€â”€ Generate agent spec
â””â”€â”€ Route to execution
```

**Tier 1 handles ~60% of commands with ZERO additional token cost.**

### Orchestrator Prompt (Tier 2)

For ambiguous tasks, this is what gets sent to classify and route:

```markdown
You are a task router for an AI development CLI. Given a user's task:

1. Classify the task type and complexity
2. Determine which department (per Intent.md) owns this
3. Determine what context is needed
4. Select the best model based on Brain query results
5. Generate a minimal agent specification

RULES:
- Prefer local models (Ollama) when they can handle the task
- Minimize context â€” only include files/data the agent actually needs
- The agent spec should be the MINIMUM effective prompt, not comprehensive
- If the task is simple enough for pattern matching, say so

Intent.md Departments: {departments_summary}
Brain Query Results: {brain_results}
User's current project context: {project_summary}
Task: {user_input}

Respond with JSON: { classification, department, context_needed, agent_spec, model, rationale }
```

---

## 7. Dynamic Agent Assembly

Instead of static prompt templates, the orchestrator generates a complete
agent specification per task. This is the heart of the architecture.

### What Gets Generated

When you run `blacksmith review src/api/auth.js`:

**Step 1: Classification** (~100 tokens via Gemini Flash)
```json
{
  "task_type": "code_review",
  "department": "engineering",
  "complexity": "medium",
  "context_needed": ["file:src/api/auth.js", "git:recent_changes", "project:package.json"],
  "estimated_context_tokens": 3200,
  "sub_agents_needed": 0,
  "model_recommendation": "gemini-2.5-pro",
  "rationale": "Code review of single file, Gemini Pro is cost-efficient for bulk reading"
}
```

**Step 2: Brain Query** (parallel notebook queries)

Results come back from `models`, `project-blacksmith`, `history-engineering`, `reference`

**Step 3: Agent Spec Generation** (~300 tokens via Gemini Flash)

```yaml
# EPHEMERAL â€” generated at runtime, torn down after
soul:
  identity: "Senior code reviewer specializing in Node.js authentication patterns"
  tone: "direct, constructive, security-focused"
  constraints:
    - "Focus on security vulnerabilities first, then correctness, then style"
    - "Flag any hardcoded secrets or insecure token handling"
    - "Reference OWASP Top 10 where applicable"

prerequisites:  # Injected from NotebookLM query results
  prior_knowledge:
    - "Previous review identified JWT expiry check missing (2026-02-26)"
    - "Auth module currently has zero test coverage"
  relevant_patterns:
    - "Express 4 middleware pattern in use"
    - "Environment variables used for secrets"

context:
  files:
    - path: "src/api/auth.js"
      role: "primary review target"
    - path: "package.json"
      role: "dependency context"
  git:
    - recent_changes: true
    - blame: "src/api/auth.js"

skills:
  - name: "file_read"
  - name: "git_log"

output:
  format: "structured_review"
  sections:
    - "Security Issues (critical â†’ low)"
    - "Correctness Issues"
    - "Suggestions"
    - "Summary Verdict"

runtime:
  model: "gemini-2.5-pro"
  max_tokens: 4000
  temperature: 0.2
  timeout: 30s
```

**Step 4: Context Assembly** (reads actual files, git data)

**Step 5: Execute** (sends assembled prompt + context to selected model)

**Step 6: Post-execution** (compress â†’ push to Brain â†’ ledger â†’ teardown)

### Why This Is Better

| Approach | Context Tokens | Quality | Cost |
|----------|---------------|---------|------|
| Static template (v1) | ~8,000 (generic) | Medium | Higher |
| OpenClaw-style (SOUL + AGENTS + memory + all skills) | ~15,000+ | Medium-High (noisy) | Highest |
| Blacksmith dynamic assembly | ~500 orchestrator + ~2,000 precise agent | High (targeted) | Lowest |

---

## 8. Sub-Agent Architecture

For complex tasks, the primary agent spawns sub-agents. Each gets its OWN
generated spec â€” minimal, focused, ephemeral. No shared context waste.

### Example: "Blacksmith, refactor the auth module to use OAuth2"

```
Orchestrator (Gemini Flash)
â”œâ”€â”€ Classifies as: complex refactor, multi-file, needs planning
â”œâ”€â”€ Department: Engineering
â”œâ”€â”€ Selects: Claude Code (agentic file editing)
â”œâ”€â”€ Generates agent spec with sub-agent definitions:
â”‚
â””â”€â”€ Primary Agent (Claude Code): "Auth Module Refactor Lead"
    â”œâ”€â”€ Sub-Agent 1 (Gemini Pro): "Research current OAuth2 best practices"
    â”‚   â””â”€â”€ Returns: structured findings (compressed)
    â”œâ”€â”€ Sub-Agent 2 (Ollama): "Analyze current auth.js for all entry points"
    â”‚   â””â”€â”€ Returns: function map + dependency graph
    â”œâ”€â”€ Sub-Agent 3 (Claude Code): "Generate refactoring plan"
    â”‚   â””â”€â”€ Returns: step-by-step plan with file changes
    â”‚
    â”‚   [Human checkpoint: "Here's the plan. Proceed?"]
    â”‚
    â”œâ”€â”€ Sub-Agent 4 (Claude Code): "Execute step 1: Install OAuth2 deps"
    â”œâ”€â”€ Sub-Agent 5 (Claude Code): "Execute step 2: Refactor token handling"
    â”œâ”€â”€ Sub-Agent 6 (Ollama): "Generate tests for new OAuth2 flow"
    â”œâ”€â”€ Sub-Agent 7 (Gemini Pro): "Review all changes for security issues"
    â”‚
    â””â”€â”€ Final: Compress results, generate summary, commit (if approved)
```

Each sub-agent is isolated. Sub-Agent 1 doesn't carry the context of
Sub-Agent 3. Different models handle different steps based on what each
step actually requires.

---

## 9. Ephemeral Agent Lifecycle

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ SCAFFOLD â”‚ Orchestrator generates agent spec
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                    â”‚ HYDRATE â”‚ Load context (files, git, prerequisites)
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                    â”‚ EXECUTE â”‚ Run agentic loop against selected model
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚ COMPRESS â”‚ Strip reasoning, extract actionable output
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                    â”‚  STORE  â”‚ Route summary to correct NotebookLM notebook(s)
                    â”‚         â”‚ Log metadata to SQLite ledger
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚ TEARDOWN â”‚ Agent spec is ephemeral â€” deleted
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 10. Task Teardown & Prerequisites System

Every completed task generates a compressed summary that routes to the
correct NotebookLM notebook(s). Future tasks query these summaries for
prerequisites, creating a compounding knowledge effect.

### Teardown Flow

```
Task Completes
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. COMPRESS OUTPUT                                          â”‚
â”‚     - Strip reasoning/thinking tokens                        â”‚
â”‚     - Extract: decisions, tools used, errors, patterns,      â”‚
â”‚       files modified, outcome                                â”‚
â”‚     - Format as structured markdown (~200-500 tokens)        â”‚
â”‚                                                              â”‚
â”‚  2. GENERATE TASK SUMMARY (/compact style)                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚     â”‚ ## Task: Code Review - src/api/auth.js              â”‚  â”‚
â”‚     â”‚ **Date**: 2026-02-26 14:32 EST                      â”‚  â”‚
â”‚     â”‚ **Model Used**: gemini-2.5-pro                      â”‚  â”‚
â”‚     â”‚ **Tokens**: 2,847 in / 1,203 out ($0.014)          â”‚  â”‚
â”‚     â”‚ **Project**: blacksmith  |  **Dept**: engineering        â”‚  â”‚
â”‚     â”‚                                                      â”‚  â”‚
â”‚     â”‚ ### Decisions                                        â”‚  â”‚
â”‚     â”‚ - JWT validation was missing expiry check            â”‚  â”‚
â”‚     â”‚ - Recommended switching from HS256 to RS256          â”‚  â”‚
â”‚     â”‚                                                      â”‚  â”‚
â”‚     â”‚ ### Patterns Discovered                              â”‚  â”‚
â”‚     â”‚ - This codebase uses Express 4 middleware pattern    â”‚  â”‚
â”‚     â”‚ - Auth module has no test coverage                   â”‚  â”‚
â”‚     â”‚                                                      â”‚  â”‚
â”‚     â”‚ ### Prerequisites for Follow-up                      â”‚  â”‚
â”‚     â”‚ - Need to generate RSA key pair before refactor      â”‚  â”‚
â”‚     â”‚ - Test framework needs setup (jest not installed)    â”‚  â”‚
â”‚     â”‚                                                      â”‚  â”‚
â”‚     â”‚ ### Tags                                             â”‚  â”‚
â”‚     â”‚ security, authentication, jwt, express, code-review  â”‚  â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  3. ROUTE TO NOTEBOOKS                                       â”‚
â”‚     â†’ history-engineering (task record)                      â”‚
â”‚     â†’ project-blacksmith (auth.js knowledge)                     â”‚
â”‚     â†’ errors (if any errors hit)                            â”‚
â”‚     â†’ models (if model escalation occurred)                 â”‚
â”‚                                                              â”‚
â”‚  4. LOG TO SQLITE LEDGER                                     â”‚
â”‚     (tokens, cost, duration, model, task type, tags)        â”‚
â”‚                                                              â”‚
â”‚  5. TEARDOWN AGENT SPEC                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Prerequisites Work

When a NEW task comes in, the orchestrator queries relevant notebooks.
Results become the `prerequisites` section injected into the agent spec.

```
User: "blacksmith refactor src/api/auth.js to use OAuth2"

Orchestrator queries history-engineering + project-blacksmith:
  â†’ Previous review found missing JWT expiry check
  â†’ Auth module has no test coverage
  â†’ Codebase uses Express 4 middleware pattern
  â†’ Need RSA key pair before refactor

These become prerequisites in the ephemeral agent spec,
so the refactoring agent starts with FULL CONTEXT of what's
already been discovered â€” without the user re-explaining.
```

### Memory Rules

Not everything gets stored. The orchestrator decides:

```yaml
always_store:
  - "Architecture decisions and rationale"
  - "User preferences discovered during interaction"
  - "Project structure maps"
  - "Error patterns and their resolutions"

never_store:
  - "Raw model reasoning/thinking tokens"
  - "Boilerplate code generation"
  - "Simple factual lookups"

compress_then_store:
  - "Research findings â†’ key conclusions + sources"
  - "Code reviews â†’ issues found + recommendations"
  - "Debug sessions â†’ root cause + fix applied"
```

---

## 11. The Compounding Loop

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                      â”‚
     â”‚   Task 1 â†’ Teardown â†’ Brain learns   â”‚
     â”‚                           â”‚           â”‚
     â”‚   Task 2 â†’ Prerequisites â”‚           â”‚
     â”‚            from Task 1    â”‚           â”‚
     â”‚            â†’ Teardown â”€â”€â”€â”€â”˜           â”‚
     â”‚                           â”‚           â”‚
     â”‚   Task 3 â†’ Prerequisites â”‚           â”‚
     â”‚            from Tasks 1+2 â”‚           â”‚
     â”‚            â†’ Teardown â”€â”€â”€â”€â”˜           â”‚
     â”‚                           â”‚           â”‚
     â”‚   Task N â†’ Prerequisites â”‚           â”‚
     â”‚            from ALL past   â”‚           â”‚
     â”‚            relevant tasks  â”‚           â”‚
     â”‚            â†’ Teardown â”€â”€â”€â”€â”˜           â”‚
     â”‚                                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     The Brain accumulates. Every task makes the next one smarter.
```

Week 1: Routes based on MCR benchmark data.
Week 4: Routes based on benchmarks + 200 task summaries.
Month 3: Knows YOUR codebase, YOUR patterns, YOUR preferences,
         YOUR error tendencies â€” all grounded in actual execution history.

No other tool does this. OpenClaw loads static memory files.
Superpowers enforces static workflows. Blacksmith GROWS.

---

## 12. Token Economics

### Scenario: Code Review of 500-line file

**Static Template Approach (v1 / OpenClaw-style):**
```
System prompt:          ~3,000 tokens (generic review instructions)
Skills/tools:           ~2,000 tokens (all skills loaded, most unused)
Memory context:         ~2,000 tokens (full conversation history)
File content:           ~2,000 tokens (the actual file)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total input:            ~9,000 tokens â†’ ~$0.027 (Gemini Pro)
Output:                 ~1,500 tokens â†’ ~$0.015
TOTAL:                  ~$0.042
```

**Blacksmith Dynamic Assembly:**
```
Orchestrator (Tier 1):  0 tokens (pattern match: "review" â†’ code_review)
Agent spec generation:  ~200 tokens via Gemini Flash â†’ ~$0.00003
Brain queries:          ~400 tokens total â†’ ~$0.0001
Context assembly:       ~2,000 tokens (file + relevant git + prerequisites)
Agent system prompt:    ~300 tokens (generated, precise)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total input:            ~2,900 tokens â†’ ~$0.004 (Gemini Pro)
Output:                 ~1,000 tokens â†’ ~$0.010 (more focused = shorter)
TOTAL:                  ~$0.014
```

**Savings: ~67% per code review.** Scale across hundreds of daily interactions.

### Token Ledger Schema

```sql
CREATE TABLE usage (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  timestamp TEXT NOT NULL DEFAULT (datetime('now')),
  backend TEXT NOT NULL,
  model TEXT,
  workflow TEXT,
  department TEXT,
  command TEXT,
  tokens_in INTEGER DEFAULT 0,
  tokens_out INTEGER DEFAULT 0,
  cost_usd REAL DEFAULT 0.0,
  duration_ms INTEGER,
  success BOOLEAN DEFAULT 1,
  escalated BOOLEAN DEFAULT 0,
  session_id TEXT,
  project TEXT
);

CREATE TABLE daily_summary (
  date TEXT PRIMARY KEY,
  total_tokens INTEGER,
  total_cost REAL,
  calls_by_backend TEXT,
  calls_by_workflow TEXT,
  calls_by_department TEXT
);

CREATE INDEX idx_usage_timestamp ON usage(timestamp);
CREATE INDEX idx_usage_backend ON usage(backend);
CREATE INDEX idx_usage_workflow ON usage(workflow);
CREATE INDEX idx_usage_project ON usage(project);
```

---

## 13. Ecosystem Borrowing

### From OpenClaw (the agent spec model)
**Take:** The SOUL.md / AGENTS.md / memory structure as a *pattern*
**Change:** Generate it per-task instead of maintaining it statically
**Skip:** Persistent daemon, messaging platforms, broad permissions,
gateway architecture, community skill marketplace

### From Superpowers (the workflow methodology)
**Take:**
- Git worktrees for isolated development branches
- Subagent-driven development (dispatch fresh agent per task step)
- Two-stage review (spec compliance â†’ code quality)
- Mandatory design â†’ plan â†’ implement flow for complex tasks
- Context-triggered skill activation

**Change:**
- Skills are generated per-task, not stored as static .md files
- Worktrees are spun up/down programmatically by the orchestrator
- Review stages use different models (cheap for spec, expensive for quality)

**Skip:** Claude Code plugin system, marketplace model

### From Research (model routing)
**Take:**
- RouterEval's finding that routing LLMs outperform single-model approaches
- Intent descriptions > terse labels for tool selection accuracy
- Cost-aware routing (40-60% savings from task-based model selection)

---

## 14. CLI Commands

### Core Workflows

```bash
# Coding
blacksmith build "REST API endpoint for user authentication using JWT"
blacksmith debug "TypeError: cannot read property 'map' of undefined"
blacksmith debug --file src/api/auth.js
blacksmith review src/api/auth.js
blacksmith review --staged
blacksmith review --pr 42
blacksmith refactor src/api/ --goal "extract shared middleware"
blacksmith commit
blacksmith commit --conventional

# Research
blacksmith research "Kubernetes vs Nomad for homelab orchestration"
blacksmith compare "Traefik" "Caddy" "Nginx Proxy Manager" --for "homelab reverse proxy"
blacksmith summarize https://arxiv.org/abs/2401.12345
blacksmith summarize ./docs/long-report.md

# Infrastructure
blacksmith deploy --env staging
blacksmith diagnose "container keeps restarting"
blacksmith diagnose --logs docker
blacksmith provision "new VLAN for IoT devices on UniFi"
```

### Brain Commands

```bash
# Query (auto-routed to correct notebooks)
blacksmith brain "how should I refactor the auth module?"
blacksmith brain "which model handles PDF parsing best?"

# Query specific notebook
blacksmith brain ask models "cheapest model for summarization"
blacksmith brain ask errors "ECONNREFUSED Docker Ollama"
blacksmith brain ask project-blacksmith "current auth architecture"

# Manage
blacksmith brain init                        # create all notebooks
blacksmith brain list                        # show notebooks + source counts
blacksmith brain sources models              # list sources in specific notebook
blacksmith brain add project-blacksmith ./doc.md  # add source to notebook
blacksmith brain project add campaignos      # create new project notebook
blacksmith brain archive history-engineering # trigger archive cycle
blacksmith brain refresh                     # re-scrape benchmark sources
blacksmith brain health                      # source counts, staleness, warnings
```

### Meta Commands

```bash
# Spend tracking
blacksmith spend
blacksmith spend --week
blacksmith spend --by-backend
blacksmith spend --by-workflow
blacksmith spend --by-department

# Configuration
blacksmith config set default-model ollama:qwen2.5-coder:7b
blacksmith config show

# MCR management
blacksmith mcr show
blacksmith mcr show --model claude-code
blacksmith mcr compare claude-code gemini-2.5-pro --for "code review"
blacksmith mcr edit
blacksmith mcr update                        # semi-automated benchmark scrape

# Project mapping
blacksmith map                               # auto-generate file tree in Intent.md

# Raw passthrough (escape hatch)
blacksmith ask "what does this regex do: ^(?=.*[A-Z])(?=.*\d).{8,}$"
blacksmith ask --backend claude "explain this architecture decision"
blacksmith ask --backend ollama "quick: default port for Redis?"
```

---

## 15. Directory Structure & Config

### File System

```
~/.blacksmith/
â”œâ”€â”€ config.yaml              # Global config
â”œâ”€â”€ brain.yaml               # Notebook registry (IDs, routing, limits)
â”œâ”€â”€ mcr.yaml                 # Model Capability Registry (local copy)
â”œâ”€â”€ Intent.md                # Organizational DNA (you write this)
â”œâ”€â”€ OrchestratorPrompt.md    # Orchestrator behavior (system + you tune)
â”œâ”€â”€ ledger.db                # SQLite â€” token usage, costs
â”œâ”€â”€ sessions/                # Active session state (ephemeral)
â”‚   â””â”€â”€ {session-id}.json
â””â”€â”€ logs/                    # Optional debug logs

# NotebookLM notebooks (managed remotely, referenced by ID in brain.yaml):
# - models
# - project-blacksmith, project-aether, project-campaignos, project-eola-gateway
# - history-engineering, history-research, history-infra, history-ops
# - errors
# - reference

~/blacksmith/                     # The CLI source
â”œâ”€â”€ package.json
â”œâ”€â”€ bin/
â”‚   â””â”€â”€ blacksmith.js             # Entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli.js               # Commander setup, command registration
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ index.js          # Main orchestration pipeline
â”‚   â”‚   â”œâ”€â”€ classifier.js     # Tier 1 (pattern match) + Tier 2 (Brain)
â”‚   â”‚   â”œâ”€â”€ agent-assembler.js # Dynamic agent spec generation
â”‚   â”‚   â”œâ”€â”€ context-loader.js  # File, git, prerequisite assembly
â”‚   â”‚   â””â”€â”€ cost-estimator.js  # Pre-execution cost estimation
â”‚   â”œâ”€â”€ brain/
â”‚   â”‚   â”œâ”€â”€ index.js           # NotebookLM client wrapper
â”‚   â”‚   â”œâ”€â”€ router.js          # Query routing (task â†’ notebooks)
â”‚   â”‚   â”œâ”€â”€ teardown-router.js # Summary routing (output â†’ notebooks)
â”‚   â”‚   â””â”€â”€ archive.js         # Lifecycle management (archive, refresh)
â”‚   â”œâ”€â”€ mcr/
â”‚   â”‚   â”œâ”€â”€ index.js           # MCR loader + query interface
â”‚   â”‚   â”œâ”€â”€ updater.js         # Semi-automated MCR updates
â”‚   â”‚   â””â”€â”€ comparator.js      # Model comparison logic
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ runner.js          # Executes generated agent specs
â”‚   â”‚   â”œâ”€â”€ sub-agent.js       # Sub-agent dispatch and coordination
â”‚   â”‚   â””â”€â”€ lifecycle.js       # Scaffold â†’ Hydrate â†’ Execute â†’ Compress â†’ Store â†’ Teardown
â”‚   â”œâ”€â”€ backends/
â”‚   â”‚   â”œâ”€â”€ claude.js          # Spawns `claude` CLI
â”‚   â”‚   â”œâ”€â”€ gemini.js          # Spawns `gemini` CLI
â”‚   â”‚   â”œâ”€â”€ codex.js           # Spawns `codex` CLI
â”‚   â”‚   â”œâ”€â”€ jules.js           # Spawns `jules` CLI
â”‚   â”‚   â”œâ”€â”€ ollama.js          # HTTP to localhost:11434
â”‚   â”‚   â””â”€â”€ github.js          # Spawns `gh` CLI
â”‚   â”œâ”€â”€ ledger/
â”‚   â”‚   â”œâ”€â”€ tracker.js         # Real-time token tracking
â”‚   â”‚   â””â”€â”€ reporter.js        # Spend analysis and reporting
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.js          # Config loader
â”‚       â”œâ”€â”€ spinner.js         # Terminal UX
â”‚       â””â”€â”€ git.js             # Git worktree management
â””â”€â”€ test/
```

### Global Config

```yaml
# ~/.blacksmith/config.yaml

version: 1

backends:
  ollama:
    enabled: true
    host: "http://localhost:11434"
    default_model: "qwen2.5-coder:7b"
    models:
      code: "qwen2.5-coder:7b"
      general: "llama3.1:8b"
      reasoning: "deepseek-r1:7b"

  claude:
    enabled: true
    default_model: "sonnet"
    max_monthly_spend: 50.00

  gemini:
    enabled: true
    default_model: "gemini-2.5-pro"

  codex:
    enabled: true

  jules:
    enabled: true

  github:
    enabled: true

routing:
  overrides:
    commit-message: ollama
    code-review: gemini
    architecture: claude
  cost_warning_threshold: 0.50
  cost_hard_stop: 2.00
  auto_escalate: true
  escalation_threshold: 0.6

brain:
  provider: "notebooklm-mcp-cli"   # or "enterprise-api"
  refresh:
    benchmarks: "weekly"
    pricing: "monthly"
    task_archive: "quarterly"

ledger:
  enabled: true
  db_path: "~/.blacksmith/ledger.db"
  daily_summary: true
  retention_days: 90

context:
  max_context:
    ollama: 4000
    claude: 100000
    gemini: 500000
    codex: 32000
  exclude:
    - "node_modules/**"
    - ".git/**"
    - "*.lock"
    - "dist/**"
    - "build/**"

logging:
  level: "info"
  save_interactions: false
```

---

## 16. Build Order

### Phase 1: The Spine (Day 1-3)
- [ ] Initialize Node.js project with Commander
- [ ] Config loader (YAML)
- [ ] MCR loader (local YAML) + `blacksmith mcr show`
- [ ] Backend wrappers: Ollama HTTP + Claude CLI spawn
- [ ] `blacksmith ask` â€” raw passthrough with basic MCR routing
- [ ] Basic ledger (log every call to SQLite)
- [ ] Install `notebooklm-mcp-cli`, authenticate
- [ ] Create initial notebooks via `blacksmith brain init`
- [ ] Seed `models` notebook with MCR data
- [ ] `blacksmith brain <query>` â€” direct NotebookLM query

**You'll have**: A CLI that routes questions to the right model and can
query NotebookLM notebooks from the terminal.

### Phase 2: The Identity (Day 4-5)
- [ ] Write Intent.md (your org DNA)
- [ ] Write initial OrchestratorPrompt.md
- [ ] Intent.md parser (extract departments, values, principles)
- [ ] Wire Intent.md into agent assembly (department â†’ agent soul)
- [ ] `blacksmith map` â€” auto-generate file tree section of Intent.md

**You'll have**: The organizational DNA that every agent inherits from.

### Phase 3: The Brain (Day 6-10)
- [ ] Tier 1 classifier (pattern matching, zero LLM cost)
- [ ] Tier 2 classifier (Brain-assisted via multi-notebook queries)
- [ ] Brain query router (task â†’ which notebooks to query)
- [ ] Dynamic agent assembler (generates per-task specs from Brain + Intent)
- [ ] Agent runner (executes specs against backends)
- [ ] Wire up remaining backends (Gemini, Codex, Jules, GitHub)
- [ ] Task Teardown pipeline:
  - Output compression
  - Summary generation
  - Route to correct notebook(s)
  - Ledger logging
- [ ] Prerequisites generation (Brain query â†’ prerequisites in agent spec)
- [ ] Core commands: `blacksmith build`, `blacksmith review`, `blacksmith debug`

**You'll have**: Smart orchestration with compounding knowledge. Each task
makes the next one smarter.

### Phase 4: The Swarm (Week 3)
- [ ] Sub-agent dispatch and coordination
- [ ] Git worktree integration (isolated branches per task)
- [ ] Multi-step workflow execution with human checkpoints
- [ ] Two-stage review (from Intent.md Engineering department config)
- [ ] `blacksmith refactor` with full sub-agent pipeline
- [ ] Jules CLI integration for async background tasks
- [ ] Escalation logic (cheap â†’ expensive, auto)
- [ ] `blacksmith commit` with Ollama

**You'll have**: Agents that build agents that do work in parallel.

### Phase 5: Polish & Self-Improvement (Week 4+)
- [ ] Routing performance analysis (every 50 tasks)
- [ ] OrchestratorPrompt.md auto-suggestions
- [ ] Tier 1 pattern learning (promote frequent Tier 2 routes)
- [ ] Notebook archive automation (quarterly merge)
- [ ] `blacksmith brain health` and `blacksmith brain refresh`
- [ ] MCR semi-automated update (`blacksmith mcr update`)
- [ ] Spend visualization (React dashboard)
- [ ] Research workflows: `blacksmith research`, `blacksmith compare`, `blacksmith summarize`
- [ ] Alternative Intent.md profiles (coding vs campaign vs grants)

**You'll have**: A self-improving system that learns from its own routing
decisions and compounds institutional knowledge.

---

## 17. Domain Agnosticism

The architecture doesn't assume coding. Intent.md defines the departments.
Change the departments, change the system.

**For a Political Campaign (CampaignOS):**
```markdown
## Departments

### Communications
- Focus: Speeches, press releases, social media, messaging
- Default models: Claude Code (writing), Gemini Pro (research)

### Policy Research
- Focus: Issue analysis, position papers, competitor analysis
- Default models: Gemini Pro (deep research), Gemini Flash (summaries)

### Voter Outreach
- Focus: Canvassing scripts, email campaigns, event planning
- Default models: Gemini Flash (high volume), Ollama (templates)

### Data & Analytics
- Focus: Polling analysis, demographic mapping, fundraising metrics
- Default models: Claude Code (analysis), Ollama (data formatting)
```

**For Grant Management (Orlando Science Center):**
```markdown
## Departments

### Grants Compliance
- Focus: Expenditure tracking, reporting, regulatory alignment
- Default models: Claude Code (precision), Gemini Pro (regulatory research)

### Proposal Development
- Focus: Grant writing, narrative development, budget justification
- Default models: Claude Code (writing), Gemini Flash (outline generation)

### Stakeholder Relations
- Focus: Communication drafts, meeting prep, impact summaries
- Default models: Gemini Flash (drafts), Ollama (quick templates)
```

Same Blacksmith. Same orchestrator. Same agent lifecycle.
Different Intent.md = different system.

---

## 18. What This Is NOT

- **Not a chat interface.** You have five of those already.
- **Not a token-burning "AI assistant."** Every call has a purpose.
- **Not a framework.** It's YOUR tool. Modify it, don't extend it.
- **Not trying to replace your IDE.** It complements your workflow.
- **Not an abstraction for abstraction's sake.** If `gh pr list` works, use it.
- **Not a persistent daemon.** It runs when you call it and exits.
- **Not a product.** It's a workshop.

---

## Naming

**Blacksmith** â€” you shape the tools, the tools shape the work.

The metaphor fits the architecture: purpose-built agents forged in the
heat of the moment, cooled down, refined output stored, mold destroyed.

Rename it to whatever fits your ecosystem. The binary is `blacksmith`, the
config lives in `~/.blacksmith/`, the source lives wherever you want it.
